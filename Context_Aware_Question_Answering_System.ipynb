{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada2505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e739e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cd355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/donur/.cache/huggingface/datasets/parquet/plain_text-b38df7ca980d7b55/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe5471d0a3141849df35487d5554a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"squad\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93af69e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrain Data Sample.....\u001b[0;0m\n",
      " \n",
      "\u001b[1mID -\u001b[0;0m 5733be284776f41900661182\n",
      "\u001b[1mTITLE - \u001b[0;0m University_of_Notre_Dame\n",
      "\u001b[1mCONTEXT - \u001b[0;0m Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "\u001b[1mANSWERS - \u001b[0;0m ['Saint Bernadette Soubirous']\n",
      "\u001b[1mANSWERS START INDEX - \u001b[0;0m [515]\n",
      " \n",
      "------------------------------------------------------------------------------------------\n",
      "\u001b[1mValidation Data Sample.....\u001b[0;0m\n",
      " \n",
      "\u001b[1mID -\u001b[0;0m 56be4db0acb8001400a502ec\n",
      "\u001b[1mTITLE - \u001b[0;0m Super_Bowl_50\n",
      "\u001b[1mCONTEXT - \u001b[0;0m Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "\u001b[1mANSWERS - \u001b[0;0m ['Denver Broncos', 'Denver Broncos', 'Denver Broncos']\n",
      "\u001b[1mANSWERS START INDEX - \u001b[0;0m [177, 177, 177]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# to make text bold\n",
    "s_bold = '\\033[1m'\n",
    "e_bold = '\\033[0;0m'\n",
    "\n",
    "print(s_bold + 'Train Data Sample.....' + e_bold)\n",
    "train_data = dataset[\"train\"]\n",
    "for data in train_data:\n",
    "    print(' ')\n",
    "    print(s_bold + 'ID -' + e_bold, data['id'])\n",
    "    print(s_bold +'TITLE - '+ e_bold, data['title'])\n",
    "    print(s_bold + 'CONTEXT - '+ e_bold,data['context'])\n",
    "    print(s_bold + 'ANSWERS - ' + e_bold,data['answers']['text'])\n",
    "    print(s_bold + 'ANSWERS START INDEX - ' + e_bold,data['answers']['answer_start'])\n",
    "    print(' ')\n",
    "    break\n",
    "\n",
    "print('---'*30)   \n",
    "print(s_bold + 'Validation Data Sample.....' + e_bold)\n",
    "train_data = dataset[\"validation\"]\n",
    "for data in train_data:\n",
    "    print(' ')\n",
    "    print(s_bold + 'ID -' + e_bold, data['id'])\n",
    "    print(s_bold +'TITLE - '+ e_bold, data['title'])\n",
    "    print(s_bold + 'CONTEXT - '+ e_bold,data['context'])\n",
    "    print(s_bold + 'ANSWERS - ' + e_bold,data['answers']['text'])\n",
    "    print(s_bold + 'ANSWERS START INDEX - ' + e_bold,data['answers']['answer_start'])\n",
    "    print(' ')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "087e6f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a81b8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93a76ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets sample a small dataset\n",
    "dataset['train'] = dataset['train'].select([i for i in range(5000)])\n",
    "dataset['validation'] = dataset['validation'].select([i for i in range(500)])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a50c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4 examples gave 2 features.\n",
      "Here is where each comes from: [0, 0].\n",
      "Question:  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      " \n",
      "Context :  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      " \n",
      "Answer:  ['Saint Bernadette Soubirous']\n",
      "--------------------------------------------------\n",
      "Context piece 1\n",
      "[SEP] architecturally, the school has a catholic character. atop the main building's gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues [SEP]\n",
      " \n",
      "Context piece 2\n",
      "[SEP] sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_checkpoint = \"bert-base-cased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "trained_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "\n",
    "context = dataset[\"train\"][0][\"context\"]\n",
    "question = dataset[\"train\"][0][\"question\"]\n",
    "answer = dataset[\"train\"][0][\"answers\"][\"text\"]\n",
    "\n",
    "\n",
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=160,\n",
    "    truncation=\"only_second\",  # only to truncate context\n",
    "    stride=70,  # no of overlapping tokens  between concecute context pieces\n",
    "    return_overflowing_tokens=True,  #to let tokenizer know we want overflow tokens\n",
    ")\n",
    "print(f\"The 4 examples gave {len(inputs['input_ids'])} features.\")\n",
    "print(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")\n",
    "\n",
    "print('Question: ',question)\n",
    "print(' ')\n",
    "print('Context : ',context)\n",
    "print(' ')\n",
    "print('Answer: ', answer)\n",
    "print('--'*25)\n",
    "\n",
    "for i,ids in enumerate(inputs[\"input_ids\"]):\n",
    "    print('Context piece', i+1)\n",
    "    print(tokenizer.decode(ids[ids.index(102):]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44fcb363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "del tokenizer\n",
    "trained_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "\n",
    "def train_data_preprocess(examples):\n",
    "    \n",
    "    \"\"\"\n",
    "    generate start and end indexes of answer in context\n",
    "    \"\"\"\n",
    "    \n",
    "    def find_context_start_end_index(sequence_ids):\n",
    "        \"\"\"\n",
    "        returns the token index in whih context starts and ends\n",
    "        \"\"\"\n",
    "        token_idx = 0\n",
    "        while sequence_ids[token_idx] != 1:  #means its special tokens or tokens of queston\n",
    "            token_idx += 1                   # loop only break when context starts in tokens\n",
    "            context_start_idx = token_idx\n",
    "        \n",
    "        while sequence_ids[token_idx] == 1:\n",
    "                token_idx += 1\n",
    "                context_end_idx = token_idx - 1\n",
    "                return context_start_idx,context_end_idx  \n",
    "\n",
    "\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    context = examples[\"context\"]\n",
    "    answers = examples[\"answers\"]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "            questions,\n",
    "            context,\n",
    "            max_length=512,\n",
    "            truncation=\"only_second\",\n",
    "            stride=128,\n",
    "            return_overflowing_tokens=True,  #returns id of base context\n",
    "            return_offsets_mapping=True,  # returns (start_index,end_index) of each token\n",
    "            padding=\"max_length\"\n",
    "            )\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for i,mapping_idx_pairs in enumerate(inputs['offset_mapping']):\n",
    "        context_idx = inputs['overflow_to_sample_mapping'][i]\n",
    "    \n",
    "        # from main context\n",
    "        answer = answers[context_idx]\n",
    "        answer_start_char_idx = answer['answer_start'][0]\n",
    "        answer_end_char_idx = answer_start_char_idx + len(answer['text'][0])\n",
    "\n",
    "    \n",
    "        # now we have to find it in sub contexts\n",
    "        tokens = inputs['input_ids'][i]\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "   \n",
    "        # finding the context start and end indexes wrt sub context tokens\n",
    "        context_start_idx,context_end_idx = find_context_start_end_index(sequence_ids)\n",
    "    \n",
    "        #if the answer is not fully inside context label it as (0,0)\n",
    "        # starting and end index of charecter of full context text\n",
    "        context_start_char_index = mapping_idx_pairs[context_start_idx][0]\n",
    "        context_end_char_index = mapping_idx_pairs[context_end_idx][1]\n",
    "        \n",
    "        #If the answer is not fully inside the context, label is (0, 0)\n",
    "        if (context_start_char_index > answer_start_char_idx) or (\n",
    "            context_end_char_index < answer_end_char_idx):\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "    \n",
    "        else:\n",
    "\n",
    "            # else its start and end token positions\n",
    "            # here idx indicates index of token\n",
    "            idx = context_start_idx\n",
    "            while idx <= context_end_idx and mapping_idx_pairs[idx][0] <= answer_start_char_idx:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)  \n",
    "            \n",
    "            idx = context_end_idx\n",
    "            while idx >= context_start_idx and mapping_idx_pairs[idx][1] > answer_end_char_idx:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "    \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "    \n",
    "train_sample = dataset[\"train\"].select([i for i in range(200)])\n",
    "    \n",
    "train_dataset = train_sample.map(\n",
    "    train_data_preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "len(dataset[\"train\"]),len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd84fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----\n",
      "Theoretical values :\n",
      " \n",
      "Question: \n",
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      " \n",
      "Context: \n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      " \n",
      "Answer: \n",
      "['Saint Bernadette Soubirous']\n",
      " \n",
      "Start and end index of text:  515 541\n",
      "--------------------------------------------------------------------------------\n",
      "Values after tokenization:\n",
      " \n",
      "Question: \n",
      "[CLS] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP]\n",
      " \n",
      "Context: \n",
      "Context: \n",
      "architecturally, the school has a catholic character. atop the main building's gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      " \n",
      "Answer: \n",
      "\n",
      " \n",
      "Start pos and end pos of tokens:  0 0\n",
      "________________________________________________________________________________\n",
      "1\n",
      "----\n",
      "Theoretical values :\n",
      " \n",
      "Question: \n",
      "What is in front of the Notre Dame Main Building?\n",
      " \n",
      "Context: \n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      " \n",
      "Answer: \n",
      "['a copper statue of Christ']\n",
      " \n",
      "Start and end index of text:  188 213\n",
      "--------------------------------------------------------------------------------\n",
      "Values after tokenization:\n",
      " \n",
      "Question: \n",
      "[CLS] what is in front of the notre dame main building? [SEP]\n",
      " \n",
      "Context: \n",
      "Context: \n",
      "architecturally, the school has a catholic character. atop the main building's gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      " \n",
      "Answer: \n",
      "\n",
      " \n",
      "Start pos and end pos of tokens:  0 0\n",
      "________________________________________________________________________________\n",
      "2\n",
      "----\n",
      "Theoretical values :\n",
      " \n",
      "Question: \n",
      "The Basilica of the Sacred heart at Notre Dame is beside to which structure?\n",
      " \n",
      "Context: \n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      " \n",
      "Answer: \n",
      "['the Main Building']\n",
      " \n",
      "Start and end index of text:  279 296\n",
      "--------------------------------------------------------------------------------\n",
      "Values after tokenization:\n",
      " \n",
      "Question: \n",
      "[CLS] the basilica of the sacred heart at notre dame is beside to which structure? [SEP]\n",
      " \n",
      "Context: \n",
      "Context: \n",
      "architecturally, the school has a catholic character. atop the main building's gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      " \n",
      "Answer: \n",
      "\n",
      " \n",
      "Start pos and end pos of tokens:  0 0\n",
      "________________________________________________________________________________\n",
      "3\n",
      "----\n",
      "Theoretical values :\n",
      " \n",
      "Question: \n",
      "What is the Grotto at Notre Dame?\n",
      " \n",
      "Context: \n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      " \n",
      "Answer: \n",
      "['a Marian place of prayer and reflection']\n",
      " \n",
      "Start and end index of text:  381 420\n",
      "--------------------------------------------------------------------------------\n",
      "Values after tokenization:\n",
      " \n",
      "Question: \n",
      "[CLS] what is the grotto at notre dame? [SEP]\n",
      " \n",
      "Context: \n",
      "Context: \n",
      "architecturally, the school has a catholic character. atop the main building's gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      " \n",
      "Answer: \n",
      "\n",
      " \n",
      "Start pos and end pos of tokens:  0 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def print_context_and_answer(idx,mini_ds=dataset[\"train\"]):  \n",
    "    print(idx)\n",
    "    print('----')\n",
    "    question = mini_ds[idx]['question']\n",
    "    context = mini_ds[idx]['context']\n",
    "    answer = mini_ds[idx]['answers']['text']\n",
    "    print('Theoretical values :')\n",
    "    print(' ')\n",
    "    print('Question: ')\n",
    "    print(question)\n",
    "    print(' ')\n",
    "    print('Context: ')\n",
    "    print(context)\n",
    "    print(' ')\n",
    "    print('Answer: ')\n",
    "    print(answer)\n",
    "    print(' ')\n",
    "    answer_start_char_idx = mini_ds[idx]['answers']['answer_start'][0]\n",
    "    answer_end_char_idx = answer_start_char_idx + len(mini_ds[idx]['answers']['text'][0])\n",
    "    print('Start and end index of text: ',answer_start_char_idx,answer_end_char_idx)\n",
    "    print('----'*20)\n",
    "    print('Values after tokenization:')\n",
    "    \n",
    "\n",
    "    #answer\n",
    "    sep_tok_index = train_dataset[idx]['input_ids'].index(102) #get index for [SEP]\n",
    "    question_ = train_dataset[idx]['input_ids'][:sep_tok_index+1]\n",
    "    question_decoded = tokenizer.decode(question_) \n",
    "    context_ = train_dataset[idx]['input_ids'][sep_tok_index+1:]\n",
    "    context_decoded = tokenizer.decode(context_) \n",
    "    start_idx = train_dataset[idx]['start_positions']\n",
    "    end_idx = train_dataset[idx]['end_positions']\n",
    "    answer_toks = train_dataset[idx]['input_ids'][start_idx:end_idx]\n",
    "    answer_decoded = tokenizer.decode(answer_toks)\n",
    "    print(' ')\n",
    "    print('Question: ')\n",
    "    print(question_decoded)\n",
    "    print(' ')\n",
    "    print('Context: ')\n",
    "    print('Context: ')\n",
    "    print(context_decoded)\n",
    "    print(' ')\n",
    "    print('Answer: ')\n",
    "    print(answer_decoded)\n",
    "    print(' ')\n",
    "    print('Start pos and end pos of tokens: ',train_dataset[idx]['start_positions'],train_dataset[idx]['end_positions'])\n",
    "    print('____'*20)\n",
    "    \n",
    "print_context_and_answer(0)\n",
    "print_context_and_answer(1)\n",
    "print_context_and_answer(2)\n",
    "print_context_and_answer(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5ffee2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def preprocess_validation_examples(examples):\n",
    "    \"\"\"\n",
    "    preprocessing validation data\n",
    "    \"\"\"\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=512,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    base_ids = []\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        \n",
    "        # take the base id (ie in cases of overflow happens we get base id)\n",
    "        base_context_idx = sample_map[i]\n",
    "        base_ids.append(examples[\"id\"][base_context_idx])\n",
    "        \n",
    "        # sequence id indicates the input. 0 for first input and 1 for second input\n",
    "        # and None for special tokens by default\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        # for Question tokens provide offset_mapping as None\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"base_id\"] = base_ids\n",
    "    return inputs\n",
    "\n",
    "# del tokenizer\n",
    "\n",
    "trained_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "\n",
    "data_val_sample = dataset[\"validation\"].select([i for i in range(100)])\n",
    "eval_set = data_val_sample.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"validation\"].column_names,\n",
    ")\n",
    "len(eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a37b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "# del tokenizer\n",
    "# take a small sample\n",
    "\n",
    "eval_set_for_model = eval_set.remove_columns([\"base_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"torch\")\n",
    "\n",
    "checkpoint =  \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n",
    "\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(checkpoint).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    \n",
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()\n",
    "\n",
    "start_logits.shape,end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c065b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f942d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import evaluate\n",
    "\n",
    "def predict_answers_and_evaluate(start_logits,end_logits,eval_set,examples):\n",
    "    \"\"\"\n",
    "    make predictions \n",
    "    Args:\n",
    "    start_logits : strat_position prediction logits\n",
    "    end_logits: end_position prediction logits\n",
    "    eval_set: processed val data\n",
    "    examples: unprocessed val data with context text\n",
    "    \"\"\"\n",
    "    # appending all id's corresponding to the base context id\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(eval_set):\n",
    "        example_to_features[feature[\"base_id\"]].append(idx)\n",
    "\n",
    "    n_best = 20\n",
    "    max_answer_length = 30\n",
    "    predicted_answers = []\n",
    "\n",
    "    for example in examples:\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # looping through each sub contexts corresponding to a context and finding\n",
    "        # answers\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = eval_set[\"offset_mapping\"][feature_index]\n",
    "        \n",
    "            # sorting the predictions of all hidden states and taking best n_best prediction\n",
    "            # means taking the index of top 20 tokens\n",
    "            start_indexes = np.argsort(start_logit).tolist()[::-1][:n_best]\n",
    "            end_indexes = np.argsort(end_logit).tolist()[::-1][:n_best]\n",
    "        \n",
    "    \n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                \n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length.\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                       ):\n",
    "                        continue\n",
    "\n",
    "                    answers.append({\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                        })\n",
    "\n",
    "    \n",
    "            # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "    \n",
    "    metric = evaluate.load(\"squad\")\n",
    "\n",
    "    theoretical_answers = [\n",
    "            {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples\n",
    "    ]\n",
    "    \n",
    "    metric_ = metric.compute(predictions=predicted_answers, references=theoretical_answers)\n",
    "    return predicted_answers,metric_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e944e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0, 'f1': 6.557418134878092}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_answers,metrics_ = predict_answers_and_evaluate(start_logits,end_logits,eval_set,data_val_sample)\n",
    "metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have very poor score as expected.\n",
    "# we can fine tune the model and will see the performance in whole validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ce169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After fine tuning,we will get approx f1 score like this\n",
    "#Exact match: 24.8, F1 score: 61.57222757290872"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
